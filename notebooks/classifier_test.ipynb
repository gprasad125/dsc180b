{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ.get(\"openai_api\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I commend all of law enforcement for the secur...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Socialist tyrant Maduro starves, tortures his ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Socialist tyrant Maduro starves, tortures his ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inhofe: The Canadians have already had convers...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Statement on Iran nuclear agreement. http://t....</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  Relevant\n",
       "0  I commend all of law enforcement for the secur...     False\n",
       "1  Socialist tyrant Maduro starves, tortures his ...      True\n",
       "2  Socialist tyrant Maduro starves, tortures his ...     False\n",
       "3  Inhofe: The Canadians have already had convers...     False\n",
       "4  Statement on Iran nuclear agreement. http://t....     False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/raw/SentimentLabeled_10112022.csv\")\n",
    "df = df[[\"text\", \"Bucket\"]]\n",
    "df[\"Relevant\"] = df[\"Bucket\"].apply(lambda x: x == \"1\")\n",
    "df.drop(columns = [\"Bucket\"], inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The President’s border-crossing permit for the A2A Railway Development Corp is a big boost for efforts to connect Alaska’s rich resources to a global market via freight rail through Canada. https://t.co/baSaeN9Lym'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/raw/SentimentLabeled_10112022.csv\")\n",
    "df[df[\"country\"] == \"Canada\"].loc[15595][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I commend all of law enforcement for the security services provided for Pope Francis’ and Chinese President Xi’s visits to the U.S.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().iloc[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isRelevant(tweet):\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    You are a machine that will be given a Tweet from a U.S. politician, and you will be asked to determine its relevancy to one of three countries. If it is relevant, return \"Relevant\" and the specific country name. Otherwise, return \"Irrelevant\".\n",
    "    \n",
    "    The three possible countries are Canada, Iran, or China. \n",
    "    A \"relevant\" tweet would discuss how ONLY one of these countries' governments is having an impact on American politics.\n",
    "\n",
    "    EXAMPLE TWEET:\n",
    "    \"They are also an assault on the American-led world order, and a disturbing premonition of an alternative world order—one controlled by the Chinese Communist Party and one that ends in Room 101.\"\n",
    "\n",
    "    EXAMPLE ANSWER: \n",
    "    Relevant, China\n",
    "\n",
    "    EXPLANATION:\n",
    "    This tweet is clearly about the Chinese government and its impact over American politics. Hence, the return value is 1. \n",
    "\n",
    "    EXAMPLE TWEET:\n",
    "    \"JUST IN: House votes to block Obama from lifting Iran sanctions https://t.co/EFI5L9WjI4\"\n",
    "\n",
    "    EXAMPLE ANSWER: \n",
    "    Irrelevant\n",
    "\n",
    "    EXPLANATION:\n",
    "    This tweet, while mentioning Iran, does not reflect any substance over Iranian political effects on America. Its ONLY focus is on America, not Iranian impacts on America, and is thus irrelvant. \n",
    "\n",
    "    EXAMPLE TWEET:\n",
    "    \"The President’s border-crossing permit for the A2A Railway Development Corp is a big boost for efforts to connect Alaska’s rich resources to a global market via freight rail through Canada. https://t.co/baSaeN9Lym\"\n",
    "\n",
    "    EXAMPLE ANSWER: \n",
    "    Relevant, Canada\n",
    "\n",
    "    EXPLANATION:\n",
    "    This tweet is about how Canadian freight reils allow for American political expansion, and is thus relevant about one of our three options.\n",
    "    \n",
    "    TWEET: \\n\n",
    "    \"\"\"\n",
    "\n",
    "    prompt += tweet + \"\\n\" + \"ANSWER: \\n\\n\"\n",
    "    \n",
    "    response = openai.Completion.create(engine = \"text-davinci-003\", prompt = prompt)\n",
    "    answer = response[\"choices\"][0][\"text\"].strip()\n",
    "    \n",
    "    return answer\n",
    "\n",
    "def cleanAnswer(response):\n",
    "   \n",
    "    try:\n",
    "        ans = response.split(\",\")\n",
    "        return ans\n",
    "    except:\n",
    "        if \"Irrelevant\" in response:\n",
    "            return response\n",
    "        else:\n",
    "            return \"There was an error. The returned string was: [\" + response + \" ]\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = df.sample(n = 100)\n",
    "subset.head()\n",
    "\n",
    "subset[\"gpt_Relevant\"] = subset[\"text\"].apply(isRelevant)\n",
    "subset[\"gpt_Relevant\"] = subset[\"gpt_Relevant\"].apply(cleanAnswer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Relevant,  China]                                  66\n",
       "[Relevant,  Iran]                                   17\n",
       "[Irrelevant]                                         9\n",
       "[Relevant,  Canada]                                  7\n",
       "[Relevant,  Russia,  China,  North Korea,  Iran]     1\n",
       "Name: gpt_Relevant, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset[\"gpt_Relevant\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial #1 accuracy: 0.77\n",
      "Trial #2 accuracy: 0.72\n",
      "Trial #3 accuracy: 0.76\n",
      "Trial #4 accuracy: 0.82\n",
      "Trial #5 accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "\n",
    "    subset = df.sample(n = 100)\n",
    "    subset.head()\n",
    "\n",
    "    subset[\"gpt_Relevant\"] = subset[\"text\"].apply(isRelevant)\n",
    "    subset[\"gpt_Relevant\"] = subset[\"gpt_Relevant\"].apply(cleanAnswer)\n",
    "\n",
    "    accuracy = (subset[\"Relevant\"] == subset[\"gpt_Relevant\"]).mean()\n",
    "    print(\"Trial #\" + str(i + 1) + \" accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Tasks for Week 4 \n",
    "# 1. Editing prompts (add more \"relevance\" explanation) \n",
    "# 2. Explore fine-tuning GPT-3 on Tweet data\n",
    "# 3. BERT Tokenizer as control group (?)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52acd9ffee7ef4a3f81d98f7c00efe030b802d860475b2f86d87171441bb69b3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
